# [ADR](./README.md) â€º Perspective-based inspection als Evaluationsmethode

<table>
<tr>
<th>status</th>
<td>proposed</td><!-- {proposed / rejected / accepted / deprecated / â€¦ / superseded by ADR-0005 <0005-example.md>} -->
</tr>
<tr>
<th>date</th>
<td>2023-04-18</td><!-- YYYY-MM-DD, when the decision was last updated -->
</tr>
<tr>
<th>deciders</th>
<td>Lining Bao</td><!-- list everyone involved in the decision -->
</tr>
<tr>
<th>consulted</th>
<td></td><!-- list everyone whose opinions are sought (typically subject-matter experts); and with whom there is a two-way communication -->
</tr>
<tr>
<th>informed</th>
<td>Katrin Hartz</td><!-- list everyone who is kept up-to-date on progress; and with whom there is a one-way communication -->
</tr>
</table>


## Kontext und Problemstellung

Im Rahmen des Projekt 1 - Konzeption wurde ein Prototyp entwickelt, der nun evaluiert werden soll. Dazu muss ein Forschungsdesign aufgestellt werden, um die DurchfÃ¼hrung der Evaluation zu ermÃ¶glichen. 

<!-- Dies ist ein optionales Element. Sie kÃ¶nnen es gerne entfernen. -->
## Entscheidungstreiber

* Bestehendes Wissen im Team
* ForschungsÃ¶konomie
* DurchfÃ¼hrbarkeit

## In Betracht gezogene Optionen

* Quantitative Datenerhebung (Umfragen)
* Usability Testing
* Experteninterviews
* Cognitive Walkthrough (perspective-based inspection)

## Ergebnis der Entscheidung

Cognitive Walkthrough (perspective-based inspection), weil es die forschungsÃ¶konomischste Variante ist.

## Pro und Kontra der Optionen

### Quantitative Datenerhebung

* ğŸŸ¢ Gut, da nicht zeit- und personenaufwÃ¤ndig
* ğŸŸ¢ Gut, da leicht remote durchfÃ¼hrbar
* ğŸŸ¡ Neutral, da durch quantitative Daten die Priorisierung der Probleme deutlicher wird
* ğŸŸ¡ Neutral, da abhÃ¤ngig von externen Personen
* ğŸ”´ Schlecht, weil es sich nicht zum Identifzieren und Nachvollziehen von Usability Problemen eignet

### Usability Testing

* ğŸŸ¢ Gut, da (teilweise) Erfahrung im Team besteht
* ğŸŸ¢ Gut, da es sich zum Identifzieren und Nachvollziehen von Usability Problemen eignet
* ğŸŸ¢ Gut, da mit echten potenziellen Nutzern getestet wird
* ğŸŸ¡ Neutral, da abhÃ¤ngig von externen Personen
* ğŸ”´ Schlecht, da Rekrutierung von geeigneten Personen sehr viel Zeit kostet
* ğŸ”´ Schlecht, da das Testing unter realen Bedingungen (in vivo) Ã¤uÃŸerst! aufwÃ¤ndig ist
* ğŸ”´ Schlecht, da die Rekrutierung von geeigneten Personen eine groÃŸe HÃ¼rde darstellt
* ğŸ”´ Schlecht, da die DurchfÃ¼hrung sehr viel Zeit in Anspruch nimmt

### Experteninterviews

* ğŸŸ¢ Gut, da unabhÃ¤ngig von externen Personen
* ğŸŸ¢ Gut, da leicht remote durchfÃ¼hrbar
* ğŸŸ¡ Neutral, da verhÃ¤ltnismÃ¤ÃŸig wenig Zeitaufwand
* ğŸŸ¡ Neutral, da mÃ¤ÃŸige Erfahrung im Team
* ğŸ”´ Schlecht, da nur Heuristiken abgedeckt werden und die in P1 identifizierten Values komplett auÃŸen vor gelassen werden
* ğŸ”´ Schlecht, da keine echten User befragt werden

### Cognitive Walkthrough (perspective-based inspection)

* ğŸŸ¢ Gut, da (teilweise) Erfahrung im Team besteht
* ğŸŸ¢ Gut, da es sich zum Identifzieren und Nachvollziehen von Usability Problemen eignet
* ğŸŸ¢ Gut, da die in P1 identifizierten Values berÃ¼cksichtigt werden kÃ¶nnen
* ğŸŸ¢ Gut, da leicht remote durchfÃ¼hrbar
* ğŸŸ¡ Neutral, da verhÃ¤ltnismÃ¤ÃŸig wenig Zeitaufwand
* ğŸŸ¡ Neutral, da die DurchfÃ¼hrung im Team aufgeteilt werden kan
* ğŸŸ¡ Neutral, da das ganze Team in der DurchfÃ¼hrung involviert werden kann
* ğŸ”´ Schlecht, da keine echten User befragt werden
